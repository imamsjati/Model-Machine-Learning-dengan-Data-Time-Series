# -*- coding: utf-8 -*-
"""Imam Sasongko_TimeSeriesSubs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LNnvyOUfADnBE10tEnMk2G9zLH3avZR7

# **Sumission Membuat Model Machine Learning dengan Data Time Series**

**Nama : Imam Sasongko Jati**

**Kelas : Belajar Pengembangan Machine Learning**

Menyiapkan dataset yang telah di unduh dari situs Kaggle [teks link](https://www.kaggle.com/fvcoppen/solarpanelspower), serta memilih kolom yang akan digunakan.
"""

import pandas as pd
df = pd.read_csv('PV_Elec_Gas3.csv')
df

"""Mengecek apakah ada nilai yang kosong dari dataset menggunakan fungsi isnull()."""

df.isnull().sum()

"""Memilih kolom 'date' dan 'Gas/day' dan memasukkanya pada dataframe baru karena yang akan dibuat adalah penggunaan gas tiap harinya."""

dt = df[['date','Gas/day']]
dt

"""Import library yang akan digunakan"""

import numpy as np
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf

"""Plot dates dan Gas/day"""

dates = dt['date'].values
gas  = dt['Gas/day'].values

dates = np.array(dates)
gas = np.array(gas) 
 
plt.figure(figsize=(20,10))
plt.plot(dates, gas)
plt.title('Gas Consumption',
          fontsize=20);

"""Split dataset dengan porsi data training (80%) dan data validasi (20%)"""

x_train, x_valid, y_train, y_valid = train_test_split(gas, dates, train_size=0.8, test_size = 0.2, shuffle = False )

print('Jumlah data train = ',len(x_train) )
print('Jumlah data validasi = ',len(x_valid) )
print('Jumlah total data = ',len(x_train)+len(x_valid))

"""Merubah data agar dapat diterima model"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

"""Membuat arsitektur model dengan menggunakan dua buah layer LSTM serta model sequential"""

train_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=1000)
val_set = windowed_dataset(x_valid, window_size=60, batch_size=100, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(60, return_sequences=True),
  tf.keras.layers.LSTM(60),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
])

"""Pada optimizer, kita akan menggunakan parameter learning rate dan momentum, serta melakukan pelatihan pada model."""

optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

history = model.fit(train_set,
                    epochs=100,
                    validation_data=val_set)

"""Plot loss dan akurasi pada saat training dan validation"""

# Plot Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()

# Plot Accuracy
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Akurasi Model')
plt.ylabel('Mae')
plt.xlabel('epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()

"""Membuat fungsi callback yang digunakan untuk menghentikan proses latihan ketika nila MAE < 10%"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae')<10):
      print("\nNilai MAE telah dibawah 10% !")
      self.model.stop_training = True
callbacks = myCallback()

"""Pelatihan model dengan fitur callback"""

model.fit(train_set, 
          epochs=100, 
          validation_data=val_set, callbacks=[callbacks])